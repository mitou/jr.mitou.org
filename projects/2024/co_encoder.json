{"@context":"https://schema.org","@type":"CreativeWork","@id":"https://jr.mitou.org/projects/2024/co_encoder","name":"Co-Encoder - LLMのためのコンテキスト圧縮エンコーダ","description":"近年、生成AIの技術は飛躍的に進展し、ChatGPTなどのLLMは自然な文章を生成できるようになりました。しかし、これらのモデルには「推論コストが高い」という課題があります。特に長文を入力する場合、膨大なメモリと高性能なGPUが必要になり、一般的なGPUでは推論が困難です。こうした課題を解決するために、行列に変換した入力を圧縮し、それを直接LLMに渡すことで低コストで長文の推論を可能にするCo-Encoderを提案します。","creator":[{"@type":"Person","name":"須田 楽大"}],"contributor":{"@type":"Person","name":"西尾 泰和","url":"https://jr.mitou.org/mentors/#hirokazu_nishio"},"video":{"@type":"VideoObject","name":"Co-Encoder - LLMのためのコンテキスト圧縮エンコーダ","embedUrl":"https://www.youtube.com/embed/El3ciW2be3s","description":"近年、生成AIの技術は飛躍的に進展し、ChatGPTなどのLLMは自然な文章を生成できるようになりました。しかし、これらのモデルには「推論コストが高い」という課題があります。特に長文を入力する場合、膨大なメモリと高性能なGPUが必要になり、一般的なGPUでは推論が困難です。こうした課題を解決するために、行列に変換した入力を圧縮し、それを直接LLMに渡すことで低コストで長文の推論を可能にするCo-Encoderを提案します。","thumbnailUrl":"/assets/img/projects/2024/co_encoder.webp","uploadDate":"2024-11-03T10:00:00+09:00"},"dateCreated":"2024-10-01T10:00:00+09:00","educationalLevel":"小中高生・高専生","inLanguage":"ja","isPartOf":{"@type":"EducationalProgram","name":"未踏ジュニア","url":"https://jr.mitou.org"}}